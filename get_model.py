# -*- coding: utf-8 -*-
import requests
import os
import json
import re
import struct
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import shutil
import threading
import subprocess
import shlex
from thread_pool import IMG_META_EXECUTOR, BG_LORA_EXECUTOR

# â˜… get_all_models.py ë¥¼ import í•˜ì§€ ì•Šê¸° ìœ„í•´ ì „ì—­ future ë¦¬ìŠ¤íŠ¸ë¥¼ ì™¸ë¶€ì—ì„œ ì£¼ì…ë°›ëŠ” êµ¬ì¡°ë¡œ ë³€ê²½
IMG_META_FUTURES = None
LORA_FUTURES = None

def set_future_lists(img_list, lora_list):
    global IMG_META_FUTURES, LORA_FUTURES
    IMG_META_FUTURES = img_list
    LORA_FUTURES = lora_list

# get_all_models.py ì—ì„œ ì£¼ì…í•´ì¤„ ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸
DOWNLOAD_TARGETS = None

def set_download_targets(target_list):
    """get_all_models.pyì—ì„œ DOWNLOAD_TARGETS ë¦¬ìŠ¤íŠ¸ë¥¼ ì£¼ì…í•´ì¤€ë‹¤."""
    global DOWNLOAD_TARGETS
    DOWNLOAD_TARGETS = target_list


###########################################################
# IDM
###########################################################
IDM_PATH = r"C:\Program Files (x86)\Internet Download Manager\IDMan.exe"


def idm_add_to_queue(url: str, save_dir: str, file_name: str):
    """
    IDM ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°ì—´ì— ì¶”ê°€ (/a)
    ë‹¤ìš´ë¡œë“œëŠ” ì•„ì§ ì‹œì‘ë˜ì§€ ì•ŠìŒ.
    """
    cmd = f'"{IDM_PATH}" /d "{url}" /p "{save_dir}" /f "{file_name}" /a'
    subprocess.Popen(shlex.split(cmd),
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL)
    print(f"[IDM] Added to queue: {file_name}")

def idm_start_download():
    """IDM ëŒ€ê¸°ì—´ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (/s)"""
    subprocess.Popen(shlex.split(f'"{IDM_PATH}" /s'),
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL)
    print("[IDM] Queue download started!")



###########################################################
# â˜… ëª¨ë“  ê²½ë¡œì˜ ê¸°ë°˜(ROOT) ë¥¼ í•œ ê³³ì—ì„œ ì •ì˜
###########################################################
ROOT = r"E:\CivitAI"   # â† ë„¤ê°€ ì›í•˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½

POSTS_ROOT = os.path.join(ROOT, "Posts")     # get_model.py â†’ ë‹¨ì¼ í¬ìŠ¤íŠ¸
USERS_ROOT = os.path.join(ROOT, "Users")     # get_all_models.py â†’ ì „ì²´ ëª¨ë¸

FILTER_SEX_PATH = os.path.join(ROOT, "Filter_Sex.txt")
FILTER_CLOTHES_PATH = os.path.join(ROOT, "Filter_Clothes.txt")
FILTER_ETC_PATH     = os.path.join(ROOT, "Filter_Etc.txt")
LORA_PASTE_TARGET_PATH = os.path.abspath(os.path.join(ROOT, "../sd/models/Lora")) # ë¡œë¼ íŒŒì¼ ë¶™ì—¬ë„£ì„ í´ë”


###########################################################
#  â˜… ì—¬ê¸°ì— ë„¤ ì¿ í‚¤ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ë³µë¶™í•´ë¼ â˜…
###########################################################
COOKIE_STRING = """
civitai-route=4fac7bdddd3d8de26621ca392c01ecaf|86d931b62a0bfdebdb632d2af59dceef; __Host-next-auth.csrf-token=dcf0009810e57b3b1f560f1b9ca9a15ad71ccc2e0fb467c8c6f035886173211b%7Cc9baf06e3cc8b8ebb284a7825d8f5754d6c555e97747cb36a53b81d683c46b9f; _sharedID=7a48cb06-1c3b-429d-b822-4539054ec690; _sharedID_cst=TyylLI8srA%3D%3D; _lr_env_src_ats=false; _ga=GA1.1.1775044621.1760120310; _cc_id=b76db4186625f576cda5f268f88e7ba8; TAPAD=%7B%22id%22%3A%225c9955fd-d70e-45aa-a642-93c810be5375%22%7D; __qca=I0-867660018-1760120320347; _ga_N6W8XF7DXE=deleted; logglytrackingsession=cd671a9f-b379-43a6-b3e8-3a03436d879f; ref_landing_page=%2Fsearch%2Fmodels%3FsortBy%3Dmodels_v9%26query%3Dclothes; panoramaId_expiry=1764931013008; panoramaId=87528db802fdd07446a3aa23bd4516d539389c900c9049bcce59b4041aedf155; panoramaIdType=panoIndiv; cto_bundle=9uWXVV9DTXRLMFlHOFdnUTFROGxjcVpyb3VIRXFEc1lZU3lrNTFuQWpUVXpnRG9ZQVZVJTJCTE1ybm9ySnh2ZmJFaW5qWCUyQlgzenRpTlRzRzVXVXk3SHRyJTJCcnY1TUc1UWppWTZoRnZwaGNBTUplVzBYS1l3RjR2Nmp4TklieG13ZXRJZkN5TWcwMng5UkkzNkVpZkJibjNRJTJGdEdhY09lMXoyVHJHRW1PR2tIb1I4N0YlMkJHaGp0VnR4NnQlMkJaSXh1UzJCYWVzdHJGcHBUZ0xQMU0lMkJxRzl5Y3E4RUtaVWclM0QlM0Q; __Secure-next-auth.callback-url=https%3A%2F%2Fcivitai.com%2Fimages%2F46561031; _sharedID_last=Sat%2C%2029%20Nov%202025%2015%3A31%3A13%20GMT; _lr_retry_request=true; civitai-route=5b7cdcef932889ec6d0f9c8f079ffd24|bf4092ed2cc1ac81a1918599cbb73e8c; __gads=ID=511ed81626cfbad7:T=1760120311:RT=1764435493:S=ALNI_MYEoURyzmRRPJ-z4HyZs99Jod_p2g; __gpi=UID=000011a1daa7c570:T=1760120311:RT=1764435493:S=ALNI_MYzvgw6Sx8g5gRotIm_7UT6ECcWiQ; __eoi=ID=60b396e298cc1fa5:T=1760120311:RT=1764435493:S=AA-AfjZJA57OxejXNdM93n8WLUQf; _ga_N6W8XF7DXE=GS2.1.s1764432295$o224$g1$t1764436352$j59$l0$h0; __Secure-civitai-token=eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0..NW5G-EP_Xc3LOFQG.8SogHo6ubxDUSdNUYRsDIILTzGg0N5oQbFyV_QF8C6q0G9d6-RbixV9oSBKwzFxvtMa-b5O8EZQd5lO4xNrSsvNEY9z9F2_yPsZ33WEkFdAzOWxqX7Fbujz1wctEE6cacSP1nWbfZGqOcAyKXBLAbqVeHAbQa8-cI4gNuhJz_d8834sMy0V-28V495G1SUPhg4RfJ4HoA3RHdpjA39we4vB-kC_Ki07V1JxVu5Wmn40Zj4A7ct8v_IGTyn-9bYGRLhwo4Y0E4-BUGN96vJqNiQQFOFEE6eg3SWx--3F-3ww0N6T26s4GwKVdbyw1-9C3M6-EpaF3hel8G_KzhyBrdlPaZWnylrlkcnqhjSvNWCMOq-9SBdH27l_WkCJNlkUeU5v3FCsp0MXX3TNK5VGnPnpQBJM7T3ThvWDI3Fo1Zw7leDqwup4DvXeuoD1ZjB0RruSmQu9BoYl48rTcaHUPW5nM0jx1WPUl3K85ZICY2qQ-EwBEWLfg-JI2PC4a7l1paTOQjDXjieEAoAMViPisJDfWWkmxzc6qv9k7RkdgQQ25oiKJceopqFdsrQTexL0ESN_O3o3uWh7u0gN8NK2P_hautx4gqSk9SmufSjcZSaGISCwmoMfoxAykaV-2VmpfSlUYrDtKDfVIroFrxX3ClJLj_y8ps9Wbdu5DFtfmqJmOEiazDh-NVJZrpDHfNC3JYLpt-d_kxz_XXjLZqcYAtbitYhPm6EIPbmAxYnujEUF9PsY8iND--lGVovHMgo9_oWn-dLVQT1QisVxmCvLV6LErOMZFqMOmCiHLmjkT7v1_2n_iNvWoITwcBdlFFwM5UuU-9GQWEqaocfZk9vtrXRPnphwjD2lcR77J0dJlTOO2HfoCESMCDBr02t0Vw0GhKshOIEj8ME1YYdKEPQxbFYF6coUSytQ2oaFIKBVi916v2YwFVt1YeMK2qmTPCfku3EvZ7KXFsBlBfSBPAMnC5Op3abhxfjZ1iDRcfSu4e13DQvQG46FL6DZ4Pq4mZhwhCVVUMA4AenFN-Dn0fQi8HNp6H0q8B3bDOlv-RwzaBATxZkKsAWt15FiPKOcwe08EQfyXBaZ30qMkJF15iqQJyi2PaYiHOI05bzEmh5yA-wAedm1_rtohat-YtEjnTUvbDB0og0-IilKbXhNEWLBee74azVHGQsAfFdQcNNdwScVJkpZ-R-E55lw6Ae3f7FeWdniVXnMBj5wPyJidhvWYJGleSgFxkJBO9OMtevdjHuexggRJvslZjC9yIyTTguq4eT6L9tHamc2Lcg3iWbLBJL74kwFFgMwnzA0c4qem1HPl6JpktffnNAVY7aoiB4QWyuxg2ARFkNhUuV9KIGp6.qkA29lO-NFGu-q6BsApo5Q
""".strip()



###########################################################
# ì´ë¯¸ì§€ ì¤‘ë³µ í™•ì¸
###########################################################
IMAGE_EXTS = {".png", ".jpg", ".jpeg", ".webp", ".gif", ".avif", ".jfif"}

def find_existing_image_by_id(folder, image_id):
    """
    í´ë” ë‚´ì—ì„œ image_idì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ì„ í™•ì¥ì ë¬´ê´€í•˜ê²Œ ì°¾ëŠ”ë‹¤.
    """
    for name in os.listdir(folder):
        base, ext = os.path.splitext(name)
        if ext.lower() in IMAGE_EXTS and base == str(image_id):
            return os.path.join(folder, name)   # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜
    return None




###########################################################
# URLë¡œë¶€í„° ì´ë¯¸ì§€ í™•ì¥ì ì¶”ì¶œ
###########################################################
def extract_image_extension(url):
    clean_url = url.split("?")[0]
    _, ext = os.path.splitext(clean_url)
    return ext.lower() if ext else ".png"



###########################################################
#  ë”œë ˆì´
###########################################################
REQUEST_LOCK = threading.Lock()
LAST_REQUEST_TIME = 0
REQUEST_INTERVAL = 1.0   # ìµœì†Œ 1ì´ˆ â€” CivitAI ì•ˆì •ê¶Œ

def safe_get(url, retries=5, **kwargs):
    global LAST_REQUEST_TIME

    for attempt in range(retries):
        with REQUEST_LOCK:

            # ìš”ì²­ ê°„ ê°„ê²© ë³´ì¥
            now = time.time()
            wait = REQUEST_INTERVAL - (now - LAST_REQUEST_TIME)
            if wait > 0:
                time.sleep(wait)

            LAST_REQUEST_TIME = time.time()

            response = session.get(url, **kwargs)

            # success
            if response.status_code != 429:
                return response

            # 429ë©´ LOCK ì•ˆì—ì„œ ëŒ€ê¸°í•´ì•¼ í•œë‹¤ (ì¤‘ìš”!)
            backoff = 2 ** attempt
            print(f"[RATE LIMIT] 429 â†’ {backoff}ì´ˆ ëŒ€ê¸°")
            time.sleep(backoff)

    raise Exception(f"429 Too Many Requests: {url}")



###########################################################
#  ì¿ í‚¤ & ì„¸ì…˜ ì„¤ì •
###########################################################
def parse_cookie_string(s: str):
    cookies = {}
    for part in s.split(";"):
        part = part.strip()
        if "=" in part:
            k, v = part.split("=", 1)
            cookies[k] = v
    return cookies


session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0",
})
session.cookies.update(parse_cookie_string(COOKIE_STRING))

BASE_IMAGE_BUCKET = "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA"


###########################################################
#  HTMLì—ì„œ í¬ìŠ¤íŠ¸ ì œëª© + modelVersionId ì¶”ì¶œ
###########################################################
def fetch_post_title_and_model_version(post_id: int):
    print("[INFO] í¬ìŠ¤íŠ¸ ì œëª© + modelVersionId ê°€ì ¸ì˜¤ëŠ” ì¤‘â€¦")
    url = f"https://civitai.com/posts/{post_id}"
    r = safe_get(url)
    r.raise_for_status()
    html = r.text

    # <title> ... | Civitai</title>
    m_title = re.search(r"<title>(.*?)\s*\|\s*Civitai</title>", html)
    if m_title:
        title = m_title.group(1).strip()
    else:
        title = f"Post_{post_id}"

    # "modelVersionId":1834089 í˜•íƒœ ì°¾ê¸°
    m_mv = re.search(r'"modelVersionId"\s*:\s*(\d+)', html)
    model_version_id = int(m_mv.group(1)) if m_mv else None

    print(f"[INFO] ì œëª© = {title}")
    print(f"[INFO] modelVersionId = {model_version_id}")
    return title, model_version_id


###########################################################
#  safetensors ë©”íƒ€ íŒŒì‹±
###########################################################
def read_safetensors_metadata(path: str):
    try:
        with open(path, "rb") as f:
            header = f.read(8)
            (json_len,) = struct.unpack("<Q", header)
            json_bytes = f.read(json_len)
            metadata = json.loads(json_bytes)
            return metadata.get("__metadata__", {})
    except Exception as e:
        print(f"[ERROR] safetensors ë©”íƒ€ ì½ê¸° ì‹¤íŒ¨: {e}")
        return {}


###########################################################
#  ë¡œë¼ íŒŒì¼ ë‚´ë¶€ì˜ ss_output_name ê°’ì— __ë¥¼ _ë¡œ ì¹˜í™˜
###########################################################
def rewrite_safetensors_metadata(path: str, new_ss_name: str):
    with open(path, "rb") as f:
        header = f.read(8)
        (json_len,) = struct.unpack("<Q", header)

        json_bytes = f.read(json_len)
        metadata = json.loads(json_bytes)

        tensor_data = f.read()  # ë‚˜ë¨¸ì§€ binary ì „ì²´
    # ë©”íƒ€ë°ì´í„° ìˆ˜ì •
    if "__metadata__" not in metadata:
        metadata["__metadata__"] = {}

    metadata["__metadata__"]["ss_output_name"] = new_ss_name

    # ìƒˆ JSON ì§ë ¬í™”
    new_json_bytes = json.dumps(metadata).encode("utf-8")
    new_json_len = struct.pack("<Q", len(new_json_bytes))

    # ìƒˆ íŒŒì¼ ì“°ê¸°
    with open(path, "wb") as f:
        f.write(new_json_len)
        f.write(new_json_bytes)
        f.write(tensor_data)


###########################################################
#  LoRA ë‹¤ìš´ë¡œë“œ presigned URL
###########################################################
def get_lora_presigned(model_version_id: int):
    url = f"https://civitai.com/api/download/models/{model_version_id}"
    r = safe_get(url, allow_redirects=False)
    if r.status_code in (302, 301, 303, 307, 308):
        loc = r.headers.get("Location")
        if not loc:
            raise RuntimeError("presigned URL ì—†ìŒ")
        return loc
    raise RuntimeError(f"presigned ìš”ì²­ ì‹¤íŒ¨: {r.status_code}")


###########################################################
#  íŒŒì¼ ë‹¤ìš´ë¡œë“œ
###########################################################
def download_file(url: str, save_path: str, retries=3):
    for attempt in range(retries):
        try:
            with safe_get(url, stream=True, timeout=10) as r:
                r.raise_for_status()
                with open(save_path, "wb") as f:
                    for chunk in r.iter_content(8192):
                        if chunk:
                            f.write(chunk)
            return True  # ì„±ê³µ
        except Exception as e:
            print(f"[ERROR] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{retries}): {e}")
            if attempt == retries - 1:
                raise
            print("  [ì¬ì‹œë„] 1ì´ˆ í›„ ì¬ì‹œë„â€¦")
            time.sleep(1)



###########################################################
#  í¬ìŠ¤íŠ¸ì˜ ì „ì²´ ì´ë¯¸ì§€ ëª©ë¡ (image.getInfinite)
###########################################################
def fetch_post_images(post_id: int):
    images = []
    cursor = None
    print("[INFO] í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª©ë¡ ìˆ˜ì§‘ ì¤‘â€¦")

    while True:
        payload = {
            "json": {
                "postId": post_id,
                "pending": True,
                "browsingLevel": None,
                "withMeta": False,
                "include": [],
                "excludedTagIds": [],
                "disablePoi": True,
                "disableMinor": True,
                "cursor": cursor,
                "authed": True
            },
            "meta": {
                "values": {
                    "browsingLevel": ["undefined"],
                    "cursor": ["undefined" if cursor is None else "string"]
                }
            }
        }

        url = "https://civitai.com/api/trpc/image.getInfinite"
        params = {"input": json.dumps(payload, separators=(",", ":"))}
        r = safe_get(url, params=params)
        r.raise_for_status()

        data = r.json()["result"]["data"]["json"]
        items = data.get("items", [])
        images.extend(items)

        cursor = data.get("nextCursor")
        if not cursor:
            break

    print(f"[INFO] ì´ {len(images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
    return images


###########################################################
#  ê°œë³„ ì´ë¯¸ì§€ GenerationData (í”„ë¡¬í”„íŠ¸ ë“±)
###########################################################
def fetch_generation(image_id: int):
    payload = json.dumps({"json": {"id": image_id, "authed": True}}, separators=(",", ":"))
    url = "https://civitai.com/api/trpc/image.getGenerationData"
    r = safe_get(url, params={"input": payload})
    r.raise_for_status()
    return r.json()["result"]["data"]["json"]


###########################################################
#  uuid â†’ ì‹¤ì œ ì´ë¯¸ì§€ URL
###########################################################
def build_image_url(uuid: str) -> str:
    return f"{BASE_IMAGE_BUCKET}/{uuid}/original=true/{uuid}.jpeg"


###########################################################
#  í”„ë¡¬í”„íŠ¸ í•„í„°ë§
###########################################################
# ---------------------------
# í•„í„° íŒŒì¼ ë¡œë“œ
# ---------------------------
def load_filter_file(path):
    words = []
    if not os.path.exists(path):
        print(f"[ê²½ê³ ] í•„í„° íŒŒì¼ ì—†ìŒ: {path}")
        return words

    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            w = line.strip()
            if w:
                words.append(w.lower())
    return words

SEX_FILTER = load_filter_file(FILTER_SEX_PATH)
CLOTHES_FILTER = load_filter_file(FILTER_CLOTHES_PATH)
ETC_FILTER = load_filter_file(FILTER_ETC_PATH)

# ì „ì²´ í•„í„° = ë‘ ê°œ í•©ì¹¨
FILTER_WORDS = SEX_FILTER + CLOTHES_FILTER + ETC_FILTER

INVALID_FS_CHARS = r'[\\/:*?"<>|]'

import re
...
def normalize_filter_item(text: str) -> str:
    """
    í•„í„° ë¹„êµ/ì¤‘ë³µ ì œê±°ìš©ìœ¼ë¡œ í† í°ì„ ì •ê·œí™”í•œë‹¤.
    ì˜ˆ:
      "(Naughty smile:0.7)"  -> "naughty smile"
      "( Naughty smile )"    -> "naughty smile"
      "Naughty smile:0.8"    -> "naughty smile"
      " Naughty  smile  "    -> "naughty smile"
    """
    if not text:
        return ""

    s = text.strip()

    # ë°”ê¹¥ í•œ ê²¹ ê´„í˜¸ ì œê±°: ( ... )
    if s.startswith("(") and s.endswith(")"):
        s = s[1:-1].strip()

    # ëì— ë¶™ì€ ê°€ì¤‘ì¹˜ ì œê±°: ":0.7", ": 0.8", ":1", ": 1.0" ë“±
    s = re.sub(r"\s*:\s*[0-9]+(?:\.[0-9]+)?\s*$", "", s)

    # ê³µë°± ì—¬ëŸ¬ ê°œ â†’ í•˜ë‚˜ë¡œ
    s = re.sub(r"\s+", " ", s)

    # í•„í„° ë¹„êµëŠ” ì†Œë¬¸ìë¡œ
    return s.lower()


def normalize_prompt_basic(prompt: str) -> str:
    if not prompt:
        return ""

    # 0) í•„ìš”í•˜ë©´ ë””ë²„ê·¸ìš© ë¡œê·¸
    if "BREAK" in prompt:
        print(f"[DEBUG] BREAK before replace: {repr(prompt)}")

    # 1) BREAK â†’ ì½¤ë§ˆ (ì •ê·œì‹ ì“°ì§€ ë§ê³  ê·¸ëƒ¥ ë¬¸ìì—´ë¡œ ë‹¤ ê°ˆì•„ë²„ë¦¬ì)
    #    ì–´ë””ì— ë¶™ì–´ìˆë“  "BREAK"ë¼ëŠ” ì—°ì† ê¸€ìê°€ ë‚˜ì˜¤ë©´ ì „ë¶€ ì½¤ë§ˆë¡œ êµì²´
    prompt = prompt.replace("BREAK", ",")

    # 2) <lora:...> íƒœê·¸ ì•ë’¤ì— ì½¤ë§ˆ ìë™ ì‚½ì…
    #    ì˜ˆ: "looking at viewer <lora:foo:1> breast"
    #      -> "looking at viewer , <lora:foo:1> , breast"
    prompt = re.sub(r"\s*(<lora:[^>]+>)\s*", r", \1, ", prompt)

    # 3) ì½¤ë§ˆ ì •ë¦¬
    #    - ì½¤ë§ˆ ê¸°ì¤€ìœ¼ë¡œ split
    #    - ì–‘ìª½ ê³µë°± ì œê±°
    #    - ë¹ˆ ë¬¸ìì—´ì€ ë²„ë¦¼ â†’ ",, ,," ê°™ì€ ê±´ ë‹¤ ì‚¬ë¼ì§
    parts = [p.strip() for p in prompt.split(",") if p.strip()]

    if not parts:
        return ""

    # ë‹¤ì‹œ ", "ë¡œ ë¶™ì—¬ì„œ ê¹”ë”í•œ í˜•íƒœë¡œ ë°˜í™˜
    return ", ".join(parts)




def clean_prompt(prompt: str, filters):
    if not prompt:
        return ""

    prompt = normalize_prompt_basic(prompt)

    # í•„í„° ë¬¸ìì—´ì„ ì •ê·œí™”í•´ì„œ í‚¤ì…‹ìœ¼ë¡œ ë§Œë“ ë‹¤.
    # ì˜ˆ: "Naughty smile", "(Naughty smile)", "Naughty smile:0.7" ì „ë¶€ "naughty smile" ë¡œ í†µì¼
    f_keys = set()
    for f in filters:
        key = normalize_filter_item(f)
        if key:
            f_keys.add(key)

    raw_tokens = [
        p.strip()
        for p in prompt.replace("\n", " ").replace("\r", " ").split(",")
    ]

    tokens = []
    for raw in raw_tokens:
        if not raw:
            tokens.append(None)
        else:
            tokens.append({
                "raw": raw,
                "lower": raw.lower(),
            })

    n = len(tokens)

    starts_group = [False] * n
    ends_group = [False] * n

    # --- ê´„í˜¸ ì‹œì‘/ì¢…ë£Œ í† í° íŒë³„ ---
    for idx, t in enumerate(tokens):
        if t is None:
            continue
        s = t["raw"]

        i = 0
        while i < len(s) and s[i].isspace():
            i += 1
        if i < len(s) and s[i] == "(":
            starts_group[idx] = True

        j = len(s) - 1
        while j >= 0 and s[j].isspace():
            j -= 1
        if j >= 0 and s[j] == ")":
            ends_group[idx] = True

    # --- ê·¸ë£¹ êµ¬ê°„ ê³„ì‚° (ì¤‘ì²© ê´„í˜¸ ê³ ë ¤) ---
    groups = []
    depth = 0
    current_start = None
    for idx in range(n):
        if tokens[idx] is None:
            continue

        if starts_group[idx]:
            if depth == 0:
                current_start = idx
            depth += 1

        if ends_group[idx] and depth > 0:
            depth -= 1
            if depth == 0 and current_start is not None:
                groups.append((current_start, idx))
                current_start = None

    in_group = [False] * n
    for s, e in groups:
        for i in range(s, e + 1):
            in_group[i] = True

    outputs = []
    idx = 0

    # --- í•„í„°ë§ ë° ì¬êµ¬ì„± ---
    while idx < n:
        t = tokens[idx]
        if t is None:
            idx += 1
            continue

        # ===== ê´„í˜¸ ì•ˆ í† í° ì²˜ë¦¬ =====
        if in_group[idx]:
            # í˜„ì¬ idx ê°€ ì†í•œ ê·¸ë£¹ ì°¾ê¸°
            start_i = end_i = idx
            for s, e in groups:
                if s == idx:
                    start_i, end_i = s, e
                    break

            kept_inners = []

            for j in range(start_i, end_i + 1):
                tj = tokens[j]
                if tj is None:
                    continue

                raw_s = tj["raw"]

                # ê·¸ë£¹ ì‹œì‘ '(' ì œê±°
                if j == start_i:
                    raw_s = raw_s.lstrip()
                    if raw_s.startswith("("):
                        raw_s = raw_s[1:]

                # ê·¸ë£¹ ë ')' ì œê±°
                if j == end_i:
                    raw_s = raw_s.rstrip()
                    if raw_s.endswith(")"):
                        raw_s = raw_s[:-1]

                inner = raw_s.strip()
                if not inner:
                    continue

                # LoRA íƒœê·¸ëŠ” ë¬´ì¡°ê±´ ìœ ì§€
                if inner.startswith("<lora:"):
                    kept_inners.append(inner)
                    continue

                # ğŸ”¹ í•„í„°ìš© ì •ê·œí™” í‚¤ë¡œ ë¹„êµ
                #    "(Naughty smile:0.7)" -> "naughty smile"
                key = normalize_filter_item(inner)
                if key and key in f_keys:
                    # í•„í„°ì— ê±¸ë ¸ìœ¼ë©´ ì œê±°
                    continue

                kept_inners.append(inner)

            if kept_inners:
                outputs.append("(" + ", ".join(kept_inners) + ")")

            idx = end_i + 1
            continue

        # ===== ê´„í˜¸ ë°– í† í° ì²˜ë¦¬ =====
        inner = t["raw"].strip()
        if not inner:
            idx += 1
            continue

        if inner.startswith("<lora:"):
            outputs.append(inner)
        else:
            key = normalize_filter_item(inner)
            if key and key in f_keys:
                # í•„í„° ëŒ€ìƒì´ë©´ ë²„ë¦°ë‹¤
                pass
            else:
                outputs.append(inner)


        idx += 1

    # 1ì°¨ ì¡°í•©
    final = ", ".join(outputs)

    if not final:
        return ""

    # 2ì°¨ ì •ë¦¬: ",, , ,, tag" ê°™ì€ ê²ƒë“¤ì„ í•˜ë‚˜ì˜ ì½¤ë§ˆ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
    #   - ì½¤ë§ˆë¡œ ë‹¤ì‹œ ë‚˜ëˆˆ ë’¤ ê³µë°±/ë¹ˆ ìš”ì†Œ ì œê±°
    parts = [p.strip() for p in final.split(",") if p.strip()]
    if not parts:
        return ""

    final = ", ".join(parts)

    # ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ë§ˆì§€ë§‰ì— ì½¤ë§ˆ í•˜ë‚˜ ìœ ì§€
    return final + ","




###########################################################
#  LoRA íƒœê·¸ ê´€ë¦¬ ìœ í‹¸
###########################################################
def remove_all_lora_tags(prompt: str) -> str:
    """í”„ë¡¬í”„íŠ¸ ì•ˆì˜ ëª¨ë“  <lora:...> íƒœê·¸ ì œê±°"""
    if not prompt:
        return ""
    return re.sub(r"<lora:[^>]+>", "", prompt).strip()


def extract_lora_from_prompt(prompt: str) -> str:
    """
    prompt ì•ˆì—ì„œ <lora:NAME:WEIGHT> í˜•íƒœì˜ íƒœê·¸ë¥¼ ì°¾ëŠ”ë‹¤.
    ì—¬ëŸ¬ ê°œë©´ ë§ˆì§€ë§‰ ê²ƒ ì‚¬ìš©. WEIGHT ì—†ìœ¼ë©´ 1ë¡œ ì²˜ë¦¬.
    ë°˜í™˜ê°’ ì˜ˆ: "<lora:Urushihara Satoshi_v3:0.8>"
    """
    if not prompt:
        return ""

    pattern = r"<lora:([^>:]+)(?::([^>]+))?>"
    matches = re.findall(pattern, prompt)
    if not matches:
        return ""

    name, weight = matches[-1]   # ë§ˆì§€ë§‰ LoRA ê¸°ì¤€
    if not weight:
        weight = "1"
    return f"<lora:{name}:{weight}>"


###########################################################
#  ì´ë¯¸ì§€ IDë¡œë¶€í„° ëª¨ë“  í¬ìŠ¤íŠ¸ ID ì–»ê¸°
###########################################################
def extract_post_ids_from_image_page(image_id):
    url = f"https://civitai.com/images/{image_id}"
    try:
        r = safe_get(url, timeout=10)
        html = r.text
    except:
        return []

    import re, json
    m = re.search(
        r'<script id="__NEXT_DATA__" type="application/json">(.+?)</script>',
        html, re.DOTALL
    )
    if not m:
        return []

    # __NEXT_DATA__ JSON íŒŒì‹±
    try:
        raw = m.group(1).strip()

        # í˜¹ì‹œ script íƒœê·¸ ì•ˆì— ì“¸ë°ì—†ëŠ” ê³µë°±/ë¬¸ì ì„ì—¬ ìˆì–´ë„
        # ì²« '{'ë¶€í„° ë§ˆì§€ë§‰ '}'ê¹Œì§€ë§Œ ì˜ë¼ì„œ ë¡œë“œ
        start = raw.find("{")
        end = raw.rfind("}")
        if start != -1 and end != -1:
            raw = raw[start:end + 1]

        data = json.loads(raw)
    except Exception as e:
        print("[WARN] __NEXT_DATA__ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

    post_ids = set()

    # JSON ì „ì²´ë¥¼ ì¬ê·€ë¡œ ëŒë©´ì„œ postId / posts / post.id ê²€ìƒ‰
    def walk(obj):
        if isinstance(obj, dict):
            # Case 1: image.postId ë˜ëŠ” ì–´ë””ë“ ì§€ ìˆëŠ” postId
            if "postId" in obj:
                pid = obj["postId"]
                if isinstance(pid, int):
                    post_ids.add(pid)

            # Case 2: posts: [{ id: ... }, ...]
            if "posts" in obj and isinstance(obj["posts"], list):
                for p in obj["posts"]:
                    if isinstance(p, dict):
                        pid = p.get("id")
                        if isinstance(pid, int):
                            post_ids.add(pid)

            # Case 3: post: { id: ... }
            if "post" in obj and isinstance(obj["post"], dict):
                pid = obj["post"].get("id")
                if isinstance(pid, int):
                    post_ids.add(pid)

            # í•˜ìœ„ ê°’ë“¤ ì¬ê·€
            for v in obj.values():
                walk(v)

        elif isinstance(obj, list):
            for v in obj:
                walk(v)

    walk(data)

    if not post_ids:
        # ë””ë²„ê·¸ìš©ìœ¼ë¡œ í•œ ë²ˆë§Œ ì°ì–´ë³´ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ì— print ì¶”ê°€í•´ë„ ë¨
        # print("[DEBUG] __NEXT_DATA__ ì—ì„œ postId ë¥¼ ì°¾ì§€ ëª»í•¨")
        return []

    return list(post_ids)


def async_process_image_meta(image_id, uuid, folder):
    try:
        gen = fetch_generation(image_id)
        meta = gen.get("meta") or {}

        resources_used = gen.get("resources") or []
        # resources_used ì•ˆì— download_endpoint ì¶”ê°€
        enriched_resources = []
        for r in resources_used:
            entry = dict(r)

            mv_id = r.get("modelVersionId")
            if mv_id:
                # presigned URLì„ ìš”ì²­í•˜ì§€ ì•Šê³ , ê³ ì • ì—”ë“œí¬ì¸íŠ¸ë§Œ ì„¤ì •
                entry["download_url"] = f"https://civitai.com/api/download/models/{mv_id}"

            enriched_resources.append(entry)

        prompt = meta.get("prompt", "") or ""
        negative = meta.get("negativePrompt", "") or ""
        cfg = meta.get("cfgScale", "")
        steps = meta.get("steps", "")
        sampler = meta.get("sampler", "")
        seed = meta.get("seed", "")
        clip_skip = meta.get("clipSkip", "")

        # ì¤„ë°”ê¿ˆ ì œê±°
        prompt = re.sub(r"[\r\n]+", " ", prompt).strip()
        negative = re.sub(r"[\r\n]+", " ", negative).strip()

        # ë¡œë¼ ì œê±°
        prompt_no_lora = remove_all_lora_tags(prompt)

        # í•„í„°ë§
        prompt_clean = clean_prompt(prompt_no_lora, FILTER_WORDS)
        prompt_with_clothes = clean_prompt(prompt_no_lora, ETC_FILTER)

        # í”„ë¡¬í”„íŠ¸ ì•ˆì— ì›ë³¸ LoRA íƒœê·¸ê°€ ìˆìœ¼ë©´ ê²€ì¶œ
        final_lora_tag = extract_lora_from_prompt(prompt)

        # LoRA íƒœê·¸ë¥¼ ì•ì— ë¶™ì´ê¸°
        if final_lora_tag:
            prompt_clean = f"{final_lora_tag}, {prompt_clean}" if prompt_clean else f"{final_lora_tag},"
            prompt_with_clothes = f"{final_lora_tag}, {prompt_with_clothes}" if prompt_with_clothes else f"{final_lora_tag},"

        meta_path = os.path.join(folder, f"{image_id}.txt")
        meta_out = {
            "prompt": prompt_clean,
            "prompt_with_clothes": prompt_with_clothes,
            "negative": negative,
            "cfg": cfg,
            "steps": steps,
            "sampler": sampler,
            "seed": seed,
            "clip_skip": clip_skip,
            "raw_prompt": prompt,
            "lora": final_lora_tag or "",
            "url": f"https://civitai.com/images/{image_id}",
            "resources_used": enriched_resources
        }

        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta_out, f, indent=2, ensure_ascii=False)

        print(f"[META] ìƒì„± ì™„ë£Œ: {meta_path}")

    except Exception as e:
        print(f"[ERROR] ë©”íƒ€ íŒŒì¼ ìƒì„± ì‹¤íŒ¨ ({image_id}): {e}")
        # ë©”íƒ€ ì‘ì—… ì‹¤íŒ¨ë„ ì‹¤íŒ¨ ë¡œê·¸ì— ë‚¨ê²¨ë‘”ë‹¤ (typeì€ imageë¡œ í†µì¼)
        try:
            import download_state
            download_state.mark_failed(
                image_id,
                "image",
                f"meta_failed: {e}",
                {
                    "folder": folder,
                    "uuid": uuid,
                    "url": f"https://civitai.com/images/{image_id}",
                    "meta_path": os.path.join(folder, f"{image_id}.txt"),
                }
            )
        except Exception:
            pass




###########################################################
#  ë‹¤ìš´ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸
###########################################################
def is_lora_downloaded(downloaded_records, model_version_id):
    if not downloaded_records:
        return False
    for item in downloaded_records.get("lora", []):
        if item["model_version_id"] == model_version_id:
            return True
    return False



def is_image_downloaded(downloaded_records, image_id):
    if not downloaded_records:
        return False
    for item in downloaded_records.get("images", []):
        if item["image_id"] == image_id:
            return True
    return False




###########################################################
#  ê³µí†µ ì½”ì–´
###########################################################
def _process_post_core(post_id: int, save_dir: str):
    """
    ê¸°ì¡´ process_post ë¡œì§ ì „ì²´ë¥¼ í¬í•¨í•œë‹¤.
    ë‹¤ë§Œ ì €ì¥ê²½ë¡œ folder ëŒ€ì‹  save_dirì„ ì‚¬ìš©í•œë‹¤.
    """
    print(f"[PROCESS] POST ì²˜ë¦¬ ì‹œì‘: {post_id}")

    # ì‹¤íŒ¨ ì •ë³´ ìˆ˜ì§‘ dict
    failed = {
        "failed_image_urls": [],
        "failed_lora": None
    }    

    # ê¸°ì¡´ ì½”ë“œ 1) ì œëª© + modelVersionId
    title, model_version_id = fetch_post_title_and_model_version(post_id)

    # ğŸ”¥ ê¸°ì¡´ì—” ì—¬ê¸°ì„œ folder = re.sub... í›„ í´ë”ë¥¼ ë§Œë“¤ì—ˆìŒ
    # ì´ì œëŠ” save_dir(ì ˆëŒ€ê²½ë¡œ)ë§Œ ì‚¬ìš©í•œë‹¤.
    folder = save_dir
    os.makedirs(folder, exist_ok=True)
    print(f"[INFO] ì €ì¥ í´ë”: {folder}")

    # 2) ì´ë¯¸ì§€ ëª©ë¡
    images = fetch_post_images(post_id)

    # ================================
    #  ë©€í‹°ì“°ë ˆë“œ LoRA ë¹„ë™ê¸° ì²˜ë¦¬
    # ================================
    lora_future = None
    sanitized_ss_name = None
    lora_tag = ""

    if model_version_id:
        print(f"[THREAD] LoRA ì‘ì—… ë¹„ë™ê¸° ì‹¤í–‰â€¦ modelVersionId={model_version_id}")
        lora_future = BG_LORA_EXECUTOR.submit(process_lora_task, folder, model_version_id, None)
        LORA_FUTURES.append(lora_future)

    else:
        print("[WARN] modelVersionId ì—†ìŒ â†’ LoRA ìŠ¤í‚µ")

    ###########################################################
    # 4) ì´ë¯¸ì§€ + ë©”íƒ€ ì²˜ë¦¬
    ###########################################################
    for idx, img in enumerate(images, 1):
        image_id = img.get("id")
        uuid = img.get("url") or img.get("uuid")

        print(f"[{idx}/{len(images)}] image_id={image_id}, uuid={uuid}")

        # =====================================================
        # ğŸš« í†µí•© ë¡œê·¸ ê¸°ë°˜ ì´ë¯¸ì§€ ì¤‘ë³µ ì²´í¬
        # =====================================================
        import download_state
        if download_state.is_success(image_id, "image"):
            print(f"[SKIP] ì´ë¯¸ì§€ ì´ë¯¸ ì„±ê³µ ë¡œê·¸ì— ìˆìŒ â†’ imageId={image_id}")
            continue
        # =====================================================


        if not uuid:
            print("  [WARN] uuid ì—†ìŒ â†’ ìŠ¤í‚µ")
            failed["failed_image_urls"].append({
                "download_url": None,
                "page_url": f"https://civitai.com/images/{image_id}"
            })
            continue

        # ì´ë¯¸ì§€ íŒŒì¼ëª…ê³¼ ë¡œì»¬ ê²½ë¡œ
        img_url = build_image_url(uuid)
        ext = extract_image_extension(img_url)
        default_filename = f"{image_id}{ext}"
        default_path = os.path.join(folder, default_filename)

        # =============================================
        # â‘  ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ ì²´í¬ â†’ ìˆìœ¼ë©´ IDM queue ì¶”ê°€í•˜ì§€ ì•ŠìŒ
        #    (í™•ì¥ì .png/.jpg/.jpeg ìƒê´€ì—†ì´ image_id ê¸°ì¤€ìœ¼ë¡œ ì°¾ìŒ)
        # =============================================
        existing_path = find_existing_image_by_id(folder, image_id)

        # ìš°ë¦¬ê°€ ì‹¤ì œë¡œ ê¸°ëŒ€í•˜ëŠ” ë¡œì»¬ íŒŒì¼ ê²½ë¡œ (í™•ì¥ì í¬í•¨)
        expected_path = existing_path or default_path

        if existing_path:
            size = os.path.getsize(existing_path)
            if size >= 3000:
                print(f"[SKIP] ì •ìƒ ì´ë¯¸ì§€ ì¡´ì¬ ({os.path.basename(existing_path)})")
                # ì´ë¯¸ í´ë”ì— ì •ìƒ íŒŒì¼ì´ ìˆìœ¼ë¯€ë¡œ ì„±ê³µ ë¡œê·¸ì— ì¶”ê°€
                try:
                    import download_state
                    download_state.mark_success(image_id, "image", existing_path, size)
                except Exception:
                    pass
            else:
                print(f"[WARN] ì†ìƒ ì´ë¯¸ì§€ ê°ì§€ ({size} bytes) â†’ ì¬ë‹¤ìš´ë¡œë“œ: {existing_path}")
                try:
                    os.remove(existing_path)
                except:
                    pass
                # ì†ìƒ íŒŒì¼ë„ ê°™ì€ ì´ë¦„ìœ¼ë¡œ ë‹¤ì‹œ ë°›ëŠ”ë‹¤
                idm_add_to_queue(img_url, folder, os.path.basename(existing_path))
        else:
            print(f"[IDM] ì‹ ê·œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ: {image_id}")
            # expected_path == default_path
            idm_add_to_queue(img_url, folder, os.path.basename(default_path))

        # ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ ëª©ë¡ì— ì¶”ê°€ (JSON ë¡œê·¸ & ìë™ ë³µêµ¬ìš©)
        #  ğŸ”¥ ì´ì œ get_all_modelsë¥¼ importí•˜ì§€ ì•Šê³ ,
        #  get_all_modelsì—ì„œ ì£¼ì…í•´ì¤€ DOWNLOAD_TARGETS ì „ì—­ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•œë‹¤.
        from get_model import DOWNLOAD_TARGETS  # ìê¸° ìì‹  ëª¨ë“ˆì˜ ì „ì—­ì„ ì°¸ì¡°

        if DOWNLOAD_TARGETS is not None:
            DOWNLOAD_TARGETS.append({
                "type": "image",
                "post_id": post_id,
                "image_id": image_id,
                "uuid": uuid,
                "download_url": img_url,
                "page_url": f"https://civitai.com/images/{image_id}",
                # âœ… ì‹¤ì œ ì¡´ì¬í•˜ëŠ”(ë˜ëŠ” ì•ìœ¼ë¡œ ë°›ì„) íŒŒì¼ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
                "expected_file_path": expected_path,
            })
        else:
            # í˜¹ì‹œë¼ë„ ì„¸íŒ…ì´ ì•ˆ ëœ ê²½ìš° ë””ë²„ê·¸ìš©
            print("[WARN] DOWNLOAD_TARGETSê°€ Noneì´ë¼ ì´ë¯¸ì§€ ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì§€ ëª»í•¨")



        # =============================================
        # â‘¡ ë©”íƒ€ ìƒì„±ì€ ë‹¤ìš´ë¡œë“œ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ ë³‘ë ¬ ì²˜ë¦¬
        # =============================================
        future = IMG_META_EXECUTOR.submit(async_process_image_meta, image_id, uuid, folder)
        IMG_META_FUTURES.append(future)

    print(f"=== POST {post_id} ì²˜ë¦¬ ì™„ë£Œ ===\n")

    return failed


def process_lora_task(folder, model_version_id, _):
    import download_state

    # 1) í†µí•© ì„±ê³µ ë¡œê·¸ ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
    if download_state.is_success(model_version_id, "lora"):
        print(f"[SKIP] ì´ë¯¸ ì„±ê³µ ë¡œê·¸ì— ìˆëŠ” LoRA â†’ modelVersionId={model_version_id}")
        return  # í•´ë‹¹ LoRA ì²˜ë¦¬ ì „ì²´ ìŠ¤í‚µ

    # 2) ëª¨ë¸ ë²„ì „ ë©”íƒ€ ë°›ì•„ì„œ íŒŒì¼ ì •ë³´ í™•ì¸
    mv_url = f"https://civitai.com/api/v1/model-versions/{model_version_id}"
    mv = safe_get(mv_url)
    mv_json = mv.json()

    safes = [f for f in mv_json.get("files", []) if f["name"].endswith(".safetensors")]
    if not safes:
        print(f"[LORA][WARN] safetensors íŒŒì¼ ì—†ìŒ â†’ modelVersionId={model_version_id}")
        return

    info = safes[0]
    remote_size = info.get("sizeKB", 0) * 1024
    lora_filename = info["name"]
    lora_path = os.path.join(folder, lora_filename)

    from get_model import DOWNLOAD_TARGETS  # ì£¼ì…ëœ ì „ì—­ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©

    if DOWNLOAD_TARGETS is not None:
        DOWNLOAD_TARGETS.append({
            "type": "lora",
            "post_id": None,  # LoRAëŠ” post_idê°€ ì—†ìœ¼ë¯€ë¡œ None
            "model_version_id": model_version_id,
            "presigned_url": None,  # presigned ì´í›„ì— ì±„ì›Œì§
            "expected_file_path": lora_path,
            "expected_file_size": remote_size,
            "final_paste_path": None,  # í›„ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì±„ì›Œì§
        })
    else:
        print("[WARN] DOWNLOAD_TARGETSê°€ Noneì´ë¼ LoRA ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì§€ ëª»í•¨")


    # 3) ğŸ”¥ ë¡œì»¬ì— ì´ë¯¸ íŒŒì¼ì´ ìˆê³ , ìš©ëŸ‰ì´ remote_size ì´ìƒì´ë©´
    #    â†’ ì„±ê³µ ë¡œê·¸ì— ì¶”ê°€ + IDM ì•ˆ íƒœìš°ê³  í›„ì²˜ë¦¬ë§Œ ì‹¤í–‰
    actual_size = 0
    if os.path.exists(lora_path):
        actual_size = os.path.getsize(lora_path)

    if os.path.exists(lora_path) and actual_size >= remote_size:
        print(f"[SKIP] LoRA ì´ë¯¸ ì¡´ì¬í•˜ê³  ì •ìƒ ìš©ëŸ‰ í™•ì¸ë¨: {lora_filename}")

        # âœ… ì—¬ê¸°ì„œ ì„±ê³µ ë¡œê·¸ì— ë“±ë¡
        try:
            download_state.mark_success(model_version_id, "lora", lora_path, actual_size)
        except Exception:
            pass

        # ì •ê·œí™” + SD í´ë” ë³µì‚¬ëŠ” ê·¸ëŒ€ë¡œ ìˆ˜í–‰
        wait_and_finalize_lora(folder, None, lora_filename)
        return

    elif os.path.exists(lora_path) and actual_size < remote_size:
        print(f"[WARN] ê¸°ì¡´ íŒŒì¼ ìš©ëŸ‰ ë¶€ì¡±({actual_size} < {remote_size}) â†’ ì¬ë‹¤ìš´ë¡œë“œ")
        try:
            os.remove(lora_path)
        except:
            pass


    presigned = get_lora_presigned(model_version_id)
    DOWNLOAD_TARGETS[-1]["presigned_url"] = presigned

    # IDM ëŒ€ê¸°ì—´ì— ì¶”ê°€
    idm_add_to_queue(presigned, folder, lora_filename)
    print(f"[IDM] LoRA ëŒ€ê¸°ì—´ì— ì¶”ê°€ë¨: {lora_filename}") 

    # âš  ì—¬ê¸°ì„œëŠ” /s í˜¸ì¶œ ì•ˆ í•¨
    # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì‹œì‘ì€ _process_post_core ë§ˆì§€ë§‰ì—ì„œ í•œ ë²ˆë§Œ í˜¸ì¶œëœë‹¤.

    # í›„ì²˜ë¦¬
    wait_and_finalize_lora(folder, presigned, lora_filename)
    
    print(f"[LORA] ì²˜ë¦¬ ì™„ë£Œ: {lora_filename}")



def wait_and_finalize_lora(folder, presigned, lora_filename):
    lora_path = os.path.join(folder, lora_filename)

    # presignedê°€ Noneì´ë©´ "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íŒŒì¼ì˜ ì‚¬í›„ì²˜ë¦¬ ëª¨ë“œ"
    if presigned is None:
        print(f"[LORA] ê¸°ì¡´ íŒŒì¼ ì‚¬í›„ ì²˜ë¦¬ ì‹œì‘: {lora_filename}")
    else:
        print(f"[IDM] LoRA ë‹¤ìš´ë¡œë“œ ëŒ€ê¸°ì¤‘: {lora_filename}")

    # ------------------------------------------------------
    # ë¡œë¼ expected_size ê²€ìƒ‰ (DOWNLOAD_TARGETSì—ì„œ ì°¾ê¸°)
    #   ğŸ”¥ ì´ì œ get_all_modelsì´ ì•„ë‹ˆë¼, get_model ì „ì—­ì—ì„œ ì£¼ì…ë°›ì€ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
    # ------------------------------------------------------
    from get_model import DOWNLOAD_TARGETS

    expected_size = None
    model_version_id = None

    if DOWNLOAD_TARGETS is not None:
        # presigned ëª¨ë“œë¼ë©´ model_version_idë¥¼ DOWNLOAD_TARGETSì—ì„œ lookup ê°€ëŠ¥
        for item in DOWNLOAD_TARGETS:
            if item["type"] == "lora" and item["expected_file_path"] == lora_path:
                expected_size = item.get("expected_file_size")
                model_version_id = item.get("model_version_id")
                break
    else:
        print("[WARN] DOWNLOAD_TARGETSê°€ Noneì´ë¼ expected_size lookup ë¶ˆê°€")


    # ------------------------------------------------------
    # ì •í™•í•œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ëŒ€ê¸° (expected_size ë¹„êµ) + íƒ€ì„ì•„ì›ƒ
    # ------------------------------------------------------
    start_ts = time.time()
    last_size = -1
    stagnant_count = 0
    TIMEOUT_SEC = 60 * 20  # 20ë¶„, í•„ìš”í•˜ë©´ ì¡°ì ˆ

    while True:
        if os.path.exists(lora_path):
            size = os.path.getsize(lora_path)

            if size != last_size:
                last_size = size
                stagnant_count = 0
            else:
                stagnant_count += 1

            if expected_size:
                # ë„ˆë¬´ ë¹¡ë¹¡í•˜ê²Œ == ë§ê³  ì–´ëŠ ì •ë„ ì—¬ìœ ë¥¼ ë‘”ë‹¤
                if size >= expected_size:
                    break
            else:
                # presignedê°€ ì—†ê³ , ìš©ëŸ‰ì´ ì¡°ê¸ˆì´ë¼ë„ ìˆê³  ì¼ì • ì‹œê°„ ë™ì•ˆ ë³€í™” ì—†ìœ¼ë©´ ì™„ë£Œë¡œ ê°„ì£¼
                if size > 0 and stagnant_count >= 3:
                    break

        # íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
        if time.time() - start_ts > TIMEOUT_SEC:
            print(f"[LORA][ERROR] ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ: {lora_filename}")
            if model_version_id:
                import download_state
                download_state.mark_failed(
                    model_version_id,
                    "lora",
                    "timeout",
                    {
                        "expected_file_path": lora_path,
                        "expected_file_size": expected_size,
                        "last_size": last_size,
                    },
                )
            return  # ë” ì´ìƒ í›„ì²˜ë¦¬ ì§„í–‰í•˜ì§€ ì•Šê³  ì¢…ë£Œ

        time.sleep(2)



    print(f"[IDM] ë‹¤ìš´ë¡œë“œ ì™„ë£Œë¨: {lora_filename}")

    # ------------------------------------------------------
    # ss_output_name ì •ê·œí™”
    #  - ìˆìœ¼ë©´: __ â†’ _ ë§Œ ì ìš©
    #  - ì—†ìœ¼ë©´: íŒŒì¼ëª…(í™•ì¥ì ì œê±°)ì„ ì •ê·œí™”(__ â†’ _) í•´ì„œ
    #             1) ss_output_name ìœ¼ë¡œ ì“°ê³ 
    #             2) ì‹¤ì œ íŒŒì¼ ì´ë¦„ë„ ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ rename
    # ------------------------------------------------------
    meta = read_safetensors_metadata(lora_path)
    ss_name = meta.get("ss_output_name")
    if isinstance(ss_name, str):
        ss_name = ss_name.strip()
    else:
        ss_name = ""

    # í˜„ì¬ lora_filename ê¸°ì¤€ ì •ê·œí™” ì´ë¦„ ê³„ì‚°
    base_name, ext = os.path.splitext(lora_filename)
    normalized_base = base_name.replace("__", "_")
    normalized_filename = normalized_base + ext

    if not ss_name:
        # ğŸ”¹ ss_output_name ì—†ìœ¼ë©´ â†’ ì •ê·œí™”ëœ íŒŒì¼ëª…(í™•ì¥ì ì œê±°)ì„ ss_output_name ìœ¼ë¡œ ì‚¬ìš©
        new_path = lora_path

        # ğŸ”¹ ì‹¤ì œ íŒŒì¼ ì´ë¦„ë„ ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ ë³€ê²½
        if normalized_filename != lora_filename:
            candidate = os.path.join(folder, normalized_filename)
            if os.path.exists(candidate):
                print(f"[LORA][WARN] ì •ê·œí™”ëœ íŒŒì¼ëª…ì´ ì´ë¯¸ ì¡´ì¬ â†’ íŒŒì¼ëª… ë³€ê²½ ìŠ¤í‚µ: {candidate}")
                # ì´ ê²½ìš°ì—ëŠ” íŒŒì¼ëª…ì€ ê·¸ëŒ€ë¡œ ë‘ê³  ss_output_nameë§Œ ë§ì¶”ê³  ê°„ë‹¤.
            else:
                os.rename(lora_path, candidate)
                print(f"[LORA] íŒŒì¼ëª… ì •ê·œí™”: {lora_filename} â†’ {normalized_filename}")
                lora_filename = normalized_filename
                new_path = candidate

        try:
            rewrite_safetensors_metadata(new_path, normalized_base)
            print(f"[LORA] ss_output_name ì—†ìŒ â†’ íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •: {normalized_base}")
        except Exception as e:
            print(f"[ERROR] ss_output_name ì„¤ì • ì‹¤íŒ¨: {e}")

        # ì´í›„ ë¡œì§ì—ì„œ ì‚¬ìš©í•  ì‹¤ì œ ê²½ë¡œ ê°±ì‹ 
        lora_path = new_path

    else:
        # ğŸ”¹ ss_output_name ì´ ì´ë¯¸ ìˆìœ¼ë©´ â†’ __ ë¥¼ _ ë¡œë§Œ ì •ê·œí™”
        sanitized = ss_name.replace("__", "_")
        try:
            rewrite_safetensors_metadata(lora_path, sanitized)
            print(f"[LORA] ss_output_name ì •ê·œí™” ì™„ë£Œ: {sanitized}")
        except Exception as e:
            print(f"[ERROR] ss_output_name ì •ê·œí™” ì‹¤íŒ¨: {e}")


    # SD í´ë”ë¡œ ë³µì‚¬
    folder_abs = os.path.abspath(folder)
    exclude_abs = os.path.abspath(ROOT)

    if folder_abs.startswith(exclude_abs):
        relative = folder_abs[len(exclude_abs):].lstrip("\\/")
    else:
        relative = os.path.basename(folder_abs)

    expected_size = expected_size or 0

    final_dir = os.path.abspath(os.path.join(LORA_PASTE_TARGET_PATH, relative))
    os.makedirs(final_dir, exist_ok=True)

    final_lora_path = os.path.join(final_dir, lora_filename)

    # -------------------------------------------------------------
    # ğŸ”¥ ê¸°ì¡´ íŒŒì¼ vs expected_size ë¹„êµí•´ì„œ ë³µì‚¬ ì—¬ë¶€ ê²°ì •
    # -------------------------------------------------------------
    need_copy = True

    if os.path.exists(final_lora_path):
        actual = os.path.getsize(final_lora_path)

        if expected_size > 0:
            if actual >= expected_size:
                print(f"[SKIP] SD í´ë”ì— ì´ë¯¸ ì •ìƒ íŒŒì¼ ì¡´ì¬: {final_lora_path}")
                need_copy = False
            else:
                print(f"[WARN] SD í´ë”ì˜ ê¸°ì¡´ íŒŒì¼ ìš©ëŸ‰ ë¶€ì¡± â†’ ì¬ë³µì‚¬ ({actual} < {expected_size})")
                try:
                    os.remove(final_lora_path)
                except:
                    pass
        else:
            # expected_sizeê°€ ì—†ìœ¼ë©´ fallback (ê¸°ì¡´ ì •ì±…)
            if actual > 0:
                need_copy = False

    # -------------------------------------------------------------
    # ğŸ”¥ ë³µì‚¬ ìˆ˜í–‰
    # -------------------------------------------------------------
    # -------------------------------------------------------------
    # ğŸ”¥ ë³µì‚¬ ìˆ˜í–‰
    # -------------------------------------------------------------
    if need_copy:
        try:
            shutil.copy2(lora_path, final_lora_path)
            print(f"[COPY] LoRA ë³µì‚¬ë¨ â†’ {final_lora_path}")
        except Exception as e:
            print(f"[LORA][ERROR] SD í´ë” ë³µì‚¬ ì‹¤íŒ¨: {e}")
            if model_version_id:
                import download_state
                download_state.mark_failed(
                    model_version_id,
                    "lora",
                    f"copy_failed: {e}",
                    {
                        "source_path": lora_path,
                        "dest_path": final_lora_path,
                        "expected_size": expected_size,
                    }
                )
            return  # ë³µì‚¬ ì‹¤íŒ¨ë©´ ì—¬ê¸°ì„œ ì¢…ë£Œ

    # âœ… ì—¬ê¸°ê¹Œì§€ ì™”ìœ¼ë©´: ë¡œë¼ íŒŒì¼ ì¡´ì¬ + ìš©ëŸ‰ OK + (í•„ìš”í•˜ë©´) SD í´ë” ë³µì‚¬ ì™„ë£Œ
    if model_version_id and os.path.exists(lora_path):
        try:
            import download_state
            size = os.path.getsize(lora_path)
            download_state.mark_success(model_version_id, "lora", lora_path, size)
        except Exception:
            pass

        except Exception as e:
            print(f"[LORA][ERROR] SD í´ë” ë³µì‚¬ ì‹¤íŒ¨: {e}")
            if model_version_id:
                import download_state
                download_state.mark_failed(
                    model_version_id,
                    "lora",
                    f"copy_failed: {e}",
                    {
                        "source_path": lora_path,
                        "dest_path": final_lora_path,
                        "expected_size": expected_size,
                    }
                )
            return  # ë³µì‚¬ ì‹¤íŒ¨ë©´ ì—¬ê¸°ì„œ ì¢…ë£Œ

    # ì—¬ê¸°ê¹Œì§€ ì™”ìœ¼ë©´ ì •ê·œí™” + ë³µì‚¬ê¹Œì§€ ì •ìƒ ì™„ë£Œ â†’ ì„±ê³µ ë¡œê·¸ì— ê¸°ë¡
    if model_version_id and os.path.exists(final_lora_path):
        try:
            import download_state
            size = os.path.getsize(final_lora_path)
            download_state.mark_success(
                model_version_id,
                "lora",
                final_lora_path,
                size
            )
        except Exception:
            pass




###########################################################
#  ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€ â€” test3.py ë‹¨ë… ì‹¤í–‰ìš©
###########################################################
def process_post(post_id: int):
    title, _ = fetch_post_title_and_model_version(post_id)

    # ì•ˆì „í•œ í´ë”ëª… ë³€í™˜
    folder_name = re.sub(INVALID_FS_CHARS, "_", title)

    # Posts/{ì œëª©}
    folder = os.path.join(POSTS_ROOT, folder_name)
    folder = os.path.abspath(folder)

    return _process_post_core(post_id, folder)


###########################################################
#  ìƒˆë¡œìš´ í•¨ìˆ˜ â€” get_all_models.py ì „ìš©
###########################################################
def process_post_to_dir(post_id: int, save_dir: str):
    """
    get_all_models.pyì—ì„œ ì‚¬ìš©í•˜ëŠ” ë²„ì „
    ì €ì¥ ê²½ë¡œëŠ” ì™„ì „íˆ save_dirë¡œ ê°•ì œë¨
    """
    save_dir = os.path.abspath(save_dir)
    return _process_post_core(post_id, save_dir)




###########################################################
#  ë©”ì¸ ì‹¤í–‰
###########################################################
if __name__ == "__main__":
    post_url = input("CivitAI í¬ìŠ¤íŠ¸ URL ì…ë ¥: ").strip()

    m = re.search(r"/posts/(\d+)", post_url)
    if not m:
        print("URLì—ì„œ postId ì¶”ì¶œ ì‹¤íŒ¨")
        raise SystemExit

    post_id = int(m.group(1))
    process_post(post_id)