# -*- coding: utf-8 -*-
import requests
import os
import json
import re
import struct
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import shutil
import threading



###########################################################
# â˜… ëª¨ë“  ê²½ë¡œì˜ ê¸°ë°˜(ROOT) ë¥¼ í•œ ê³³ì—ì„œ ì •ì˜
###########################################################
ROOT = r"E:\CivitAI"   # â† ë„¤ê°€ ì›í•˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½

POSTS_ROOT = os.path.join(ROOT, "Posts")     # get_model.py â†’ ë‹¨ì¼ í¬ìŠ¤íŠ¸
USERS_ROOT = os.path.join(ROOT, "Users")     # get_all_models.py â†’ ì „ì²´ ëª¨ë¸

FILTER_CLOTHES_PATH = os.path.join(ROOT, "Filter_Clothes.txt")
FILTER_ETC_PATH     = os.path.join(ROOT, "Filter_Etc.txt")
LORA_PASTE_TARGET_PATH = os.path.abspath(os.path.join(ROOT, "../sd/models/Lora")) # ë¡œë¼ íŒŒì¼ ë¶™ì—¬ë„£ì„ í´ë”


###########################################################
#  â˜… ì—¬ê¸°ì— ë„¤ ì¿ í‚¤ ì „ì²´ë¥¼ ê·¸ëŒ€ë¡œ ë³µë¶™í•´ë¼ â˜…
###########################################################
COOKIE_STRING = """
civitai-route=4fac7bdddd3d8de26621ca392c01ecaf|86d931b62a0bfdebdb632d2af59dceef; __Host-next-auth.csrf-token=dcf0009810e57b3b1f560f1b9ca9a15ad71ccc2e0fb467c8c6f035886173211b%7Cc9baf06e3cc8b8ebb284a7825d8f5754d6c555e97747cb36a53b81d683c46b9f; _sharedID=7a48cb06-1c3b-429d-b822-4539054ec690; _sharedID_cst=TyylLI8srA%3D%3D; _lr_env_src_ats=false; _ga=GA1.1.1775044621.1760120310; _cc_id=b76db4186625f576cda5f268f88e7ba8; TAPAD=%7B%22id%22%3A%225c9955fd-d70e-45aa-a642-93c810be5375%22%7D; __qca=I0-867660018-1760120320347; _ga_N6W8XF7DXE=deleted; logglytrackingsession=cd671a9f-b379-43a6-b3e8-3a03436d879f; ref_landing_page=%2Fsearch%2Fmodels%3FsortBy%3Dmodels_v9%26query%3Dclothes; panoramaId_expiry=1764931013008; panoramaId=87528db802fdd07446a3aa23bd4516d539389c900c9049bcce59b4041aedf155; panoramaIdType=panoIndiv; cto_bundle=9uWXVV9DTXRLMFlHOFdnUTFROGxjcVpyb3VIRXFEc1lZU3lrNTFuQWpUVXpnRG9ZQVZVJTJCTE1ybm9ySnh2ZmJFaW5qWCUyQlgzenRpTlRzRzVXVXk3SHRyJTJCcnY1TUc1UWppWTZoRnZwaGNBTUplVzBYS1l3RjR2Nmp4TklieG13ZXRJZkN5TWcwMng5UkkzNkVpZkJibjNRJTJGdEdhY09lMXoyVHJHRW1PR2tIb1I4N0YlMkJHaGp0VnR4NnQlMkJaSXh1UzJCYWVzdHJGcHBUZ0xQMU0lMkJxRzl5Y3E4RUtaVWclM0QlM0Q; __Secure-next-auth.callback-url=https%3A%2F%2Fcivitai.com%2Fimages%2F46561031; _sharedID_last=Sat%2C%2029%20Nov%202025%2015%3A31%3A13%20GMT; _lr_retry_request=true; civitai-route=5b7cdcef932889ec6d0f9c8f079ffd24|bf4092ed2cc1ac81a1918599cbb73e8c; __gads=ID=511ed81626cfbad7:T=1760120311:RT=1764435493:S=ALNI_MYEoURyzmRRPJ-z4HyZs99Jod_p2g; __gpi=UID=000011a1daa7c570:T=1760120311:RT=1764435493:S=ALNI_MYzvgw6Sx8g5gRotIm_7UT6ECcWiQ; __eoi=ID=60b396e298cc1fa5:T=1760120311:RT=1764435493:S=AA-AfjZJA57OxejXNdM93n8WLUQf; _ga_N6W8XF7DXE=GS2.1.s1764432295$o224$g1$t1764436352$j59$l0$h0; __Secure-civitai-token=eyJhbGciOiJkaXIiLCJlbmMiOiJBMjU2R0NNIn0..NW5G-EP_Xc3LOFQG.8SogHo6ubxDUSdNUYRsDIILTzGg0N5oQbFyV_QF8C6q0G9d6-RbixV9oSBKwzFxvtMa-b5O8EZQd5lO4xNrSsvNEY9z9F2_yPsZ33WEkFdAzOWxqX7Fbujz1wctEE6cacSP1nWbfZGqOcAyKXBLAbqVeHAbQa8-cI4gNuhJz_d8834sMy0V-28V495G1SUPhg4RfJ4HoA3RHdpjA39we4vB-kC_Ki07V1JxVu5Wmn40Zj4A7ct8v_IGTyn-9bYGRLhwo4Y0E4-BUGN96vJqNiQQFOFEE6eg3SWx--3F-3ww0N6T26s4GwKVdbyw1-9C3M6-EpaF3hel8G_KzhyBrdlPaZWnylrlkcnqhjSvNWCMOq-9SBdH27l_WkCJNlkUeU5v3FCsp0MXX3TNK5VGnPnpQBJM7T3ThvWDI3Fo1Zw7leDqwup4DvXeuoD1ZjB0RruSmQu9BoYl48rTcaHUPW5nM0jx1WPUl3K85ZICY2qQ-EwBEWLfg-JI2PC4a7l1paTOQjDXjieEAoAMViPisJDfWWkmxzc6qv9k7RkdgQQ25oiKJceopqFdsrQTexL0ESN_O3o3uWh7u0gN8NK2P_hautx4gqSk9SmufSjcZSaGISCwmoMfoxAykaV-2VmpfSlUYrDtKDfVIroFrxX3ClJLj_y8ps9Wbdu5DFtfmqJmOEiazDh-NVJZrpDHfNC3JYLpt-d_kxz_XXjLZqcYAtbitYhPm6EIPbmAxYnujEUF9PsY8iND--lGVovHMgo9_oWn-dLVQT1QisVxmCvLV6LErOMZFqMOmCiHLmjkT7v1_2n_iNvWoITwcBdlFFwM5UuU-9GQWEqaocfZk9vtrXRPnphwjD2lcR77J0dJlTOO2HfoCESMCDBr02t0Vw0GhKshOIEj8ME1YYdKEPQxbFYF6coUSytQ2oaFIKBVi916v2YwFVt1YeMK2qmTPCfku3EvZ7KXFsBlBfSBPAMnC5Op3abhxfjZ1iDRcfSu4e13DQvQG46FL6DZ4Pq4mZhwhCVVUMA4AenFN-Dn0fQi8HNp6H0q8B3bDOlv-RwzaBATxZkKsAWt15FiPKOcwe08EQfyXBaZ30qMkJF15iqQJyi2PaYiHOI05bzEmh5yA-wAedm1_rtohat-YtEjnTUvbDB0og0-IilKbXhNEWLBee74azVHGQsAfFdQcNNdwScVJkpZ-R-E55lw6Ae3f7FeWdniVXnMBj5wPyJidhvWYJGleSgFxkJBO9OMtevdjHuexggRJvslZjC9yIyTTguq4eT6L9tHamc2Lcg3iWbLBJL74kwFFgMwnzA0c4qem1HPl6JpktffnNAVY7aoiB4QWyuxg2ARFkNhUuV9KIGp6.qkA29lO-NFGu-q6BsApo5Q
""".strip()



###########################################################
#  ë”œë ˆì´
###########################################################
RATE_LIMIT_DELAY = 0.3  # 300ms

def safe_get(url, **kwargs):
    """ì „ì—­ì ìœ¼ë¡œ rate-limit ë”œë ˆì´ë¥¼ ì ìš©í•œ GET ìš”ì²­"""
    time.sleep(RATE_LIMIT_DELAY)
    return session.get(url, **kwargs)


###########################################################
#  ì¿ í‚¤ & ì„¸ì…˜ ì„¤ì •
###########################################################
def parse_cookie_string(s: str):
    cookies = {}
    for part in s.split(";"):
        part = part.strip()
        if "=" in part:
            k, v = part.split("=", 1)
            cookies[k] = v
    return cookies


session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0",
})
session.cookies.update(parse_cookie_string(COOKIE_STRING))

BASE_IMAGE_BUCKET = "https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7WA"


###########################################################
#  HTMLì—ì„œ í¬ìŠ¤íŠ¸ ì œëª© + modelVersionId ì¶”ì¶œ
###########################################################
def fetch_post_title_and_model_version(post_id: int):
    print("[INFO] í¬ìŠ¤íŠ¸ ì œëª© + modelVersionId ê°€ì ¸ì˜¤ëŠ” ì¤‘â€¦")
    url = f"https://civitai.com/posts/{post_id}"
    r = safe_get(url)
    r.raise_for_status()
    html = r.text

    # <title> ... | Civitai</title>
    m_title = re.search(r"<title>(.*?)\s*\|\s*Civitai</title>", html)
    if m_title:
        title = m_title.group(1).strip()
    else:
        title = f"Post_{post_id}"

    # "modelVersionId":1834089 í˜•íƒœ ì°¾ê¸°
    m_mv = re.search(r'"modelVersionId"\s*:\s*(\d+)', html)
    model_version_id = int(m_mv.group(1)) if m_mv else None

    print(f"[INFO] ì œëª© = {title}")
    print(f"[INFO] modelVersionId = {model_version_id}")
    return title, model_version_id


###########################################################
#  safetensors ë©”íƒ€ íŒŒì‹±
###########################################################
def read_safetensors_metadata(path: str):
    try:
        with open(path, "rb") as f:
            header = f.read(8)
            (json_len,) = struct.unpack("<Q", header)
            json_bytes = f.read(json_len)
            metadata = json.loads(json_bytes)
            return metadata.get("__metadata__", {})
    except Exception as e:
        print(f"[ERROR] safetensors ë©”íƒ€ ì½ê¸° ì‹¤íŒ¨: {e}")
        return {}


###########################################################
#  ë¡œë¼ íŒŒì¼ ë‚´ë¶€ì˜ ss_output_name ê°’ì— __ë¥¼ _ë¡œ ì¹˜í™˜
###########################################################
def rewrite_safetensors_metadata(path: str, new_ss_name: str):
    with open(path, "rb") as f:
        header = f.read(8)
        (json_len,) = struct.unpack("<Q", header)

        json_bytes = f.read(json_len)
        metadata = json.loads(json_bytes)

        tensor_data = f.read()  # ë‚˜ë¨¸ì§€ binary ì „ì²´
    # ë©”íƒ€ë°ì´í„° ìˆ˜ì •
    if "__metadata__" not in metadata:
        metadata["__metadata__"] = {}

    metadata["__metadata__"]["ss_output_name"] = new_ss_name

    # ìƒˆ JSON ì§ë ¬í™”
    new_json_bytes = json.dumps(metadata).encode("utf-8")
    new_json_len = struct.pack("<Q", len(new_json_bytes))

    # ìƒˆ íŒŒì¼ ì“°ê¸°
    with open(path, "wb") as f:
        f.write(new_json_len)
        f.write(new_json_bytes)
        f.write(tensor_data)


###########################################################
#  LoRA ë‹¤ìš´ë¡œë“œ presigned URL
###########################################################
def get_lora_presigned(model_version_id: int):
    url = f"https://civitai.com/api/download/models/{model_version_id}"
    r = safe_get(url, allow_redirects=False)
    if r.status_code in (302, 301, 303, 307, 308):
        loc = r.headers.get("Location")
        if not loc:
            raise RuntimeError("presigned URL ì—†ìŒ")
        return loc
    raise RuntimeError(f"presigned ìš”ì²­ ì‹¤íŒ¨: {r.status_code}")


###########################################################
#  íŒŒì¼ ë‹¤ìš´ë¡œë“œ
###########################################################
def download_file(url: str, save_path: str, retries=3):
    for attempt in range(retries):
        try:
            with safe_get(url, stream=True, timeout=10) as r:
                r.raise_for_status()
                with open(save_path, "wb") as f:
                    for chunk in r.iter_content(8192):
                        if chunk:
                            f.write(chunk)
            return True  # ì„±ê³µ
        except Exception as e:
            print(f"[ERROR] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{retries}): {e}")
            if attempt == retries - 1:
                raise
            print("  [ì¬ì‹œë„] 1ì´ˆ í›„ ì¬ì‹œë„â€¦")
            time.sleep(1)



###########################################################
#  í¬ìŠ¤íŠ¸ì˜ ì „ì²´ ì´ë¯¸ì§€ ëª©ë¡ (image.getInfinite)
###########################################################
def fetch_post_images(post_id: int):
    images = []
    cursor = None
    print("[INFO] í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ëª©ë¡ ìˆ˜ì§‘ ì¤‘â€¦")

    while True:
        payload = {
            "json": {
                "postId": post_id,
                "pending": True,
                "browsingLevel": None,
                "withMeta": False,
                "include": [],
                "excludedTagIds": [],
                "disablePoi": True,
                "disableMinor": True,
                "cursor": cursor,
                "authed": True
            },
            "meta": {
                "values": {
                    "browsingLevel": ["undefined"],
                    "cursor": ["undefined" if cursor is None else "string"]
                }
            }
        }

        url = "https://civitai.com/api/trpc/image.getInfinite"
        params = {"input": json.dumps(payload, separators=(",", ":"))}
        r = safe_get(url, params=params)
        r.raise_for_status()

        data = r.json()["result"]["data"]["json"]
        items = data.get("items", [])
        images.extend(items)

        cursor = data.get("nextCursor")
        if not cursor:
            break

    print(f"[INFO] ì´ {len(images)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
    return images


###########################################################
#  ê°œë³„ ì´ë¯¸ì§€ GenerationData (í”„ë¡¬í”„íŠ¸ ë“±)
###########################################################
def fetch_generation(image_id: int):
    payload = json.dumps({"json": {"id": image_id, "authed": True}}, separators=(",", ":"))
    url = "https://civitai.com/api/trpc/image.getGenerationData"
    r = safe_get(url, params={"input": payload})
    r.raise_for_status()
    return r.json()["result"]["data"]["json"]


###########################################################
#  uuid â†’ ì‹¤ì œ ì´ë¯¸ì§€ URL
###########################################################
def build_image_url(uuid: str) -> str:
    return f"{BASE_IMAGE_BUCKET}/{uuid}/original=true/{uuid}.jpeg"


###########################################################
#  í”„ë¡¬í”„íŠ¸ í•„í„°ë§
###########################################################
# ---------------------------
# í•„í„° íŒŒì¼ ë¡œë“œ
# ---------------------------
def load_filter_file(path):
    words = []
    if not os.path.exists(path):
        print(f"[ê²½ê³ ] í•„í„° íŒŒì¼ ì—†ìŒ: {path}")
        return words

    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            w = line.strip()
            if w:
                words.append(w.lower())
    return words

CLOTHES_FILTER = load_filter_file(FILTER_CLOTHES_PATH)
ETC_FILTER = load_filter_file(FILTER_ETC_PATH)

# ì „ì²´ í•„í„° = ë‘ ê°œ í•©ì¹¨
FILTER_WORDS = CLOTHES_FILTER + ETC_FILTER

INVALID_FS_CHARS = r'[\\/:*?"<>|]'

def clean_prompt(prompt: str, filters):
    if not prompt:
        return ""

    f_low = [f.lower() for f in filters]

    raw_tokens = [
        p.strip()
        for p in prompt.replace("\n", " ").replace("\r", " ").split(",")
    ]

    tokens = []
    for raw in raw_tokens:
        if not raw:
            tokens.append(None)
        else:
            tokens.append({
                "raw": raw,
                "lower": raw.lower(),
            })

    n = len(tokens)

    starts_group = [False] * n
    ends_group = [False] * n

    # --- ê´„í˜¸ ì‹œì‘/ì¢…ë£Œ í† í° íŒë³„ ---
    for idx, t in enumerate(tokens):
        if t is None:
            continue
        s = t["raw"]

        i = 0
        while i < len(s) and s[i].isspace():
            i += 1
        if i < len(s) and s[i] == "(":
            starts_group[idx] = True

        j = len(s) - 1
        while j >= 0 and s[j].isspace():
            j -= 1
        if j >= 0 and s[j] == ")":
            ends_group[idx] = True

    # --- ê·¸ë£¹ ë²”ìœ„ íƒìƒ‰ ---
    groups = []
    depth = 0
    current_start = None
    for idx in range(n):
        if tokens[idx] is None:
            continue

        if starts_group[idx]:
            if depth == 0:
                current_start = idx
            depth += 1

        if ends_group[idx] and depth > 0:
            depth -= 1
            if depth == 0 and current_start is not None:
                groups.append((current_start, idx))
                current_start = None

    in_group = [False] * n
    for s, e in groups:
        for i in range(s, e + 1):
            in_group[i] = True

    outputs = []
    idx = 0

    # --- í•„í„°ë§ ë° ì¬êµ¬ì„± ---
    while idx < n:
        t = tokens[idx]
        if t is None:
            idx += 1
            continue

        if in_group[idx]:
            for s, e in groups:
                if s == idx:
                    start_i, end_i = s, e
                    break

            kept_inners = []

            for j in range(start_i, end_i + 1):
                tj = tokens[j]
                if tj is None:
                    continue

                raw_s = tj["raw"]

                # ê·¸ë£¹ ì‹œì‘ '(' ì œê±°
                if j == start_i:
                    if raw_s.startswith("("):
                        raw_s = raw_s[1:]

                # ê·¸ë£¹ ë ')' ì œê±°
                if j == end_i:
                    if raw_s.endswith(")"):
                        raw_s = raw_s[:-1]

                inner = raw_s.strip()
                if not inner:
                    continue

                inner_low = inner.lower()

                # LoRA íƒœê·¸ëŠ” ë¬´ì¡°ê±´ ìœ ì§€
                if inner.startswith("<lora:"):
                    kept_inners.append(inner)
                    continue

                # í•„í„° ë‹¨ì–´ í¬í•¨ â†’ ì œê±°
                if any(f in inner_low for f in f_low):
                    continue

                kept_inners.append(inner)

            if kept_inners:
                outputs.append("(" + ", ".join(kept_inners) + ")")

            idx = end_i + 1
            continue

        # --- ê´„í˜¸ ì™¸ë¶€ í† í° ì²˜ë¦¬ ---
        inner = t["raw"].strip()
        if not inner:
            idx += 1
            continue

        inner_low = inner.lower()

        if inner.startswith("<lora:"):
            outputs.append(inner)
        elif any(f in inner_low for f in f_low):
            pass
        else:
            outputs.append(inner)

        idx += 1

    final = ", ".join(outputs)
    return final + ("," if final else "")


###########################################################
#  LoRA íƒœê·¸ ê´€ë¦¬ ìœ í‹¸
###########################################################
def remove_all_lora_tags(prompt: str) -> str:
    """í”„ë¡¬í”„íŠ¸ ì•ˆì˜ ëª¨ë“  <lora:...> íƒœê·¸ ì œê±°"""
    if not prompt:
        return ""
    return re.sub(r"<lora:[^>]+>", "", prompt).strip()


def extract_lora_from_prompt(prompt: str) -> str:
    """
    prompt ì•ˆì—ì„œ <lora:NAME:WEIGHT> í˜•íƒœì˜ íƒœê·¸ë¥¼ ì°¾ëŠ”ë‹¤.
    ì—¬ëŸ¬ ê°œë©´ ë§ˆì§€ë§‰ ê²ƒ ì‚¬ìš©. WEIGHT ì—†ìœ¼ë©´ 1ë¡œ ì²˜ë¦¬.
    ë°˜í™˜ê°’ ì˜ˆ: "<lora:Urushihara Satoshi_v3:0.8>"
    """
    if not prompt:
        return ""

    pattern = r"<lora:([^>:]+)(?::([^>]+))?>"
    matches = re.findall(pattern, prompt)
    if not matches:
        return ""

    name, weight = matches[-1]   # ë§ˆì§€ë§‰ LoRA ê¸°ì¤€
    if not weight:
        weight = "1"
    return f"<lora:{name}:{weight}>"


###########################################################
#  ì´ë¯¸ì§€ IDë¡œë¶€í„° ëª¨ë“  í¬ìŠ¤íŠ¸ ID ì–»ê¸°
###########################################################
def extract_post_ids_from_image_page(image_id):
    url = f"https://civitai.com/images/{image_id}"
    try:
        r = safe_get(url, timeout=10)
        html = r.text
    except:
        return []

    import re, json
    m = re.search(
        r'<script id="__NEXT_DATA__" type="application/json">(.+?)</script>',
        html, re.DOTALL
    )
    if not m:
        return []

    # __NEXT_DATA__ JSON íŒŒì‹±
    try:
        raw = m.group(1).strip()

        # í˜¹ì‹œ script íƒœê·¸ ì•ˆì— ì“¸ë°ì—†ëŠ” ê³µë°±/ë¬¸ì ì„ì—¬ ìˆì–´ë„
        # ì²« '{'ë¶€í„° ë§ˆì§€ë§‰ '}'ê¹Œì§€ë§Œ ì˜ë¼ì„œ ë¡œë“œ
        start = raw.find("{")
        end = raw.rfind("}")
        if start != -1 and end != -1:
            raw = raw[start:end + 1]

        data = json.loads(raw)
    except Exception as e:
        print("[WARN] __NEXT_DATA__ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        return []

    post_ids = set()

    # JSON ì „ì²´ë¥¼ ì¬ê·€ë¡œ ëŒë©´ì„œ postId / posts / post.id ê²€ìƒ‰
    def walk(obj):
        if isinstance(obj, dict):
            # Case 1: image.postId ë˜ëŠ” ì–´ë””ë“ ì§€ ìˆëŠ” postId
            if "postId" in obj:
                pid = obj["postId"]
                if isinstance(pid, int):
                    post_ids.add(pid)

            # Case 2: posts: [{ id: ... }, ...]
            if "posts" in obj and isinstance(obj["posts"], list):
                for p in obj["posts"]:
                    if isinstance(p, dict):
                        pid = p.get("id")
                        if isinstance(pid, int):
                            post_ids.add(pid)

            # Case 3: post: { id: ... }
            if "post" in obj and isinstance(obj["post"], dict):
                pid = obj["post"].get("id")
                if isinstance(pid, int):
                    post_ids.add(pid)

            # í•˜ìœ„ ê°’ë“¤ ì¬ê·€
            for v in obj.values():
                walk(v)

        elif isinstance(obj, list):
            for v in obj:
                walk(v)

    walk(data)

    if not post_ids:
        # ë””ë²„ê·¸ìš©ìœ¼ë¡œ í•œ ë²ˆë§Œ ì°ì–´ë³´ê³  ì‹¶ìœ¼ë©´ ì—¬ê¸°ì— print ì¶”ê°€í•´ë„ ë¨
        # print("[DEBUG] __NEXT_DATA__ ì—ì„œ postId ë¥¼ ì°¾ì§€ ëª»í•¨")
        return []

    return list(post_ids)





###########################################################
#  ê³µí†µ ì½”ì–´
###########################################################
def _process_post_core(post_id: int, save_dir: str):
    """
    ê¸°ì¡´ process_post ë¡œì§ ì „ì²´ë¥¼ í¬í•¨í•œë‹¤.
    ë‹¤ë§Œ ì €ì¥ê²½ë¡œ folder ëŒ€ì‹  save_dirì„ ì‚¬ìš©í•œë‹¤.
    """
    print(f"[PROCESS] POST ì²˜ë¦¬ ì‹œì‘: {post_id}")

    # ì‹¤íŒ¨ ì •ë³´ ìˆ˜ì§‘ dict
    failed = {
        "failed_image_urls": [],
        "failed_lora": None
    }    

    # ê¸°ì¡´ ì½”ë“œ 1) ì œëª© + modelVersionId
    title, model_version_id = fetch_post_title_and_model_version(post_id)

    # ğŸ”¥ ê¸°ì¡´ì—” ì—¬ê¸°ì„œ folder = re.sub... í›„ í´ë”ë¥¼ ë§Œë“¤ì—ˆìŒ
    # ì´ì œëŠ” save_dir(ì ˆëŒ€ê²½ë¡œ)ë§Œ ì‚¬ìš©í•œë‹¤.
    folder = save_dir
    os.makedirs(folder, exist_ok=True)
    print(f"[INFO] ì €ì¥ í´ë”: {folder}")

    # 2) ì´ë¯¸ì§€ ëª©ë¡
    images = fetch_post_images(post_id)

    # ================================
    #  ë©€í‹°ì“°ë ˆë“œ LoRA ë¹„ë™ê¸° ì²˜ë¦¬
    # ================================
    lora_future = None
    sanitized_ss_name = None
    lora_tag = ""

    if model_version_id:
        print(f"[THREAD] LoRA ì‘ì—… ë¹„ë™ê¸° ì‹¤í–‰â€¦ modelVersionId={model_version_id}")

        # LoRA ì‘ì—…ì„ ì¦‰ì‹œ ë¹„ë™ê¸° ì‹¤í–‰ (ëŒ€ê¸°í•˜ì§€ ì•ŠìŒ)
        executor = ThreadPoolExecutor(max_workers=1)
        lora_future = executor.submit(process_lora_task, folder, model_version_id, None)

    else:
        print("[WARN] modelVersionId ì—†ìŒ â†’ LoRA ìŠ¤í‚µ")

    ###########################################################
    # 4) ì´ë¯¸ì§€ + ë©”íƒ€ ì²˜ë¦¬
    ###########################################################
    for idx, img in enumerate(images, 1):
        image_id = img.get("id")
        uuid = img.get("url") or img.get("uuid")

        print(f"[{idx}/{len(images)}] image_id={image_id}, uuid={uuid}")

        if not uuid:
            print("  [WARN] uuid ì—†ìŒ â†’ ìŠ¤í‚µ")
            continue

        # ì €ì¥ ê²½ë¡œ
        img_filename = f"{image_id}.png"
        img_path = os.path.join(folder, img_filename)

        img_url = build_image_url(uuid)

        # ğŸ”¥ íŒŒì¼ í¬ê¸° ì²´í¬ â†’ 100KB(=102400 bytes) ë¯¸ë§Œì´ë©´ ì¬ë‹¤ìš´ë¡œë“œ
        if os.path.exists(img_path):
            size = os.path.getsize(img_path)
            if size < 102400:  # 100KB ë¯¸ë§Œ
                print(f"[INFO] ì´ë¯¸ì§€ íŒŒì¼ í¬ê¸° {size} bytes â†’ ë„ˆë¬´ ì‘ìŒ, ì¬ë‹¤ìš´ë¡œë“œ ì§„í–‰")

                try:
                    os.remove(img_path)
                    print("  [INFO] ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
                except Exception as e:
                    print(f"  [ERROR] ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

                # ì¬ë‹¤ìš´ë¡œë“œ ì‹œë„
                try:
                    download_file(img_url, img_path)
                    print("  [INFO] ì¬ë‹¤ìš´ë¡œë“œ ì„±ê³µ")
                except Exception as e:
                    print(f"  [ERROR] ì¬ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    failed["failed_image_urls"].append({
                        "download_url": img_url,
                        "page_url": f"https://civitai.com/images/{image_id}"
                    })
                    continue

                # ë‹¤ìš´ë¡œë“œ ì„±ê³µí–ˆìœ¼ë©´ ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰
                # (ê¸°ë³¸ ë¡œì§ ê³„ì†)
                # GenerationData ì²˜ë¦¬ë¡œ ë„˜ì–´ê°„ë‹¤.
                # ë”°ë¼ì„œ ì•„ë˜ else ë¸”ë¡ SKIP
                pass

            else:
                print(f"[SKIP] ì´ë¯¸ì§€ ì´ë¯¸ ì¡´ì¬: {img_filename}")
        else:
            print(f"[Download] {img_filename}")
            try:
                try:
                    download_file(img_url, img_path)
                except Exception:
                    failed["failed_image_urls"].append({
                        "download_url": img_url,
                        "page_url": f"https://civitai.com/images/{image_id}"
                    })
                    continue
            except Exception as e:
                print(f"[ERROR] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue

        # GenerationData
        try:
            gen = fetch_generation(image_id)
        except Exception as e:
            print(f"  [ERROR] GenerationData ì‹¤íŒ¨: {e}")
            continue

        meta = gen.get("meta") or {}
        
        resources_used = gen.get("resources") or []
        prompt = meta.get("prompt", "") or ""
        negative = meta.get("negativePrompt", "") or ""
        cfg = meta.get("cfgScale", "")
        steps = meta.get("steps", "")
        sampler = meta.get("sampler", "")
        seed = meta.get("seed", "")
        clip_skip = meta.get("clipSkip", "")

        prompt = re.sub(r"[\r\n]+", " ", prompt).strip()
        negative = re.sub(r"[\r\n]+", " ", negative).strip()

        # ğŸ”¥ prompt ë‚´ë¶€ì˜ ë¡œë¼ë¥¼ ë¨¼ì € ëª¨ë‘ ì œê±°í•´ì•¼ clean_promptê°€ ë¬¸ì œ ì—†ì´ ë™ì‘í•¨
        prompt_no_lora = remove_all_lora_tags(prompt)

        # 1) ë¡œë¼ ì œê±°ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
        prompt_clean = clean_prompt(prompt_no_lora, FILTER_WORDS)
        prompt_with_clothes = clean_prompt(prompt_no_lora, ETC_FILTER)

        # 3) raw í”„ë¡¬í”„íŠ¸(prompt) ì—ì„œ LoRA íƒœê·¸ ë‹¤ì‹œ ì¶”ì¶œ
        final_lora_tag = extract_lora_from_prompt(prompt)

        # raw í”„ë¡¬í”„íŠ¸ì— LoRAê°€ ì—†ë‹¤ë©´, safetensors ë©”íƒ€ì—ì„œ ë³´ì •ìš©ìœ¼ë¡œ í•œ ë²ˆ ë” ì‹œë„
        if not final_lora_tag and sanitized_ss_name:
            base_name = sanitized_ss_name.split(":")[0]  # ì´ë¦„ë§Œ ì‚¬ìš©
            final_lora_tag = f"<lora:{base_name}:1>"

        # 4) ìµœì¢… LoRA íƒœê·¸ë¥¼ prompt_* ì— ë°˜ì˜
        if final_lora_tag:
            if prompt_clean:
                prompt_clean = f"{final_lora_tag}, {prompt_clean}"
            else:
                prompt_clean = f"{final_lora_tag},"

            if prompt_with_clothes:
                prompt_with_clothes = f"{final_lora_tag}, {prompt_with_clothes}"
            else:
                prompt_with_clothes = f"{final_lora_tag},"
        else:
            final_lora_tag = ""

        meta_path = os.path.join(folder, f"{image_id}.txt")
        meta_out = {
            "prompt": prompt_clean,
            "prompt_with_clothes": prompt_with_clothes,
            "negative": negative,
            "cfg": cfg,
            "steps": steps,
            "sampler": sampler,
            "seed": seed,
            "clip_skip": clip_skip,
            "raw_prompt": prompt,
            "lora": "",
            "url": f"https://civitai.com/images/{image_id}",
            "resources_used": resources_used
        }

        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta_out, f, indent=2, ensure_ascii=False)

        print(f"  [META] ì €ì¥: {meta_path}\n")

    print(f"=== POST {post_id} ì²˜ë¦¬ ì™„ë£Œ ===\n")

    return failed


def process_lora_task(folder, model_version_id, failed_dict_lock):
    """
    ë©€í‹°ì“°ë ˆë“œë¡œ ì‹¤í–‰ë˜ëŠ” LoRA ì²˜ë¦¬ í•¨ìˆ˜
    - presigned URL ì–»ê¸°
    - ë‹¤ìš´ë¡œë“œ
    - ss_output_name ì •ê·œí™”
    - ìµœì¢… í´ë” ë³µì‚¬
    - ì‹¤íŒ¨ì •ë³´ëŠ” dict í˜•íƒœë¡œ ë¦¬í„´
    """

    result = {
        "failed_lora": None,
        "lora_tag": "",
        "sanitized_ss_name": None
    }

    try:
        # 1) model-versions ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        mv_url = f"https://civitai.com/api/v1/model-versions/{model_version_id}"
        mv = safe_get(mv_url)
        mv.raise_for_status()
        mv_json = mv.json()

        files = mv_json.get("files", [])
        safes = [f for f in files if f.get("name","").endswith(".safetensors")]

        if not safes:
            print("[WARN] safetensors íŒŒì¼ ì—†ìŒ")
            return result

        # ì²« safetensors íŒŒì¼ë§Œ ìš°ì„  ì²˜ë¦¬ (ë‚˜ì¤‘ì— ì „ë¶€ ì²˜ë¦¬ë¡œ í™•ëŒ€ ê°€ëŠ¥)
        info = safes[0]
        lora_filename = info["name"]

        # 2) presigned URL ì–»ê¸°
        try:
            presigned = get_lora_presigned(model_version_id)
        except Exception as e:
            result["failed_lora"] = {
                "lora_url": None,
                "copy_error": f"presigned ì‹¤íŒ¨: {e}"
            }
            return result

        # 3) ë‹¤ìš´ë¡œë“œ ê²½ë¡œ
        lora_path = os.path.join(folder, lora_filename)

        # ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ)
        if not os.path.exists(lora_path):
            try:
                download_file(presigned, lora_path)
            except Exception as e:
                result["failed_lora"] = {
                    "lora_url": presigned,
                    "copy_error": f"LoRA ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}"
                }
                return result
        else:
            print(f"[INFO] LoRA ì´ë¯¸ ìˆìŒ: {lora_filename}")

        # 4) ss_output_name ì½ê¸° â†’ ì •ê·œí™”
        meta = read_safetensors_metadata(lora_path)
        ss_name = meta.get("ss_output_name")
        if ss_name:
            sanitized = ss_name.replace("__", "_")
            rewrite_safetensors_metadata(lora_path, sanitized)
            result["sanitized_ss_name"] = sanitized
            result["lora_tag"] = f"<lora:{sanitized}:1>"
        else:
            result["sanitized_ss_name"] = None

        # 5) Stable Diffusion í´ë”ë¡œ ë³µì‚¬
        folder_abs = os.path.abspath(folder)
        exclude_abs = os.path.abspath(ROOT)

        if folder_abs.startswith(exclude_abs):
            relative = folder_abs[len(exclude_abs):].lstrip("\\/")
        else:
            relative = os.path.basename(folder_abs)

        final_dir = os.path.abspath(os.path.join(LORA_PASTE_TARGET_PATH, relative))
        os.makedirs(final_dir, exist_ok=True)

        final_lora_path = os.path.join(final_dir, lora_filename)

        if not os.path.exists(final_lora_path):
            try:
                shutil.copy2(lora_path, final_lora_path)
            except Exception as e:
                result["failed_lora"] = {
                    "lora_url": presigned,
                    "copy_error": f"LoRA ë³µì‚¬ ì‹¤íŒ¨: {e}"
                }
        else:
            print(f"[SKIP] ìµœì¢… ê²½ë¡œì— ì´ë¯¸ ì¡´ì¬: {final_lora_path}")

    except Exception as e:
        result["failed_lora"] = {"copy_error": str(e)}

    return result



###########################################################
#  ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€ â€” test3.py ë‹¨ë… ì‹¤í–‰ìš©
###########################################################
def process_post(post_id: int):
    title, _ = fetch_post_title_and_model_version(post_id)

    # ì•ˆì „í•œ í´ë”ëª… ë³€í™˜
    folder_name = re.sub(INVALID_FS_CHARS, "_", title)

    # Posts/{ì œëª©}
    folder = os.path.join(POSTS_ROOT, folder_name)
    folder = os.path.abspath(folder)

    return _process_post_core(post_id, folder)


###########################################################
#  ìƒˆë¡œìš´ í•¨ìˆ˜ â€” get_all_models.py ì „ìš©
###########################################################
def process_post_to_dir(post_id: int, save_dir: str):
    """
    get_all_models.pyì—ì„œ ì‚¬ìš©í•˜ëŠ” ë²„ì „
    ì €ì¥ ê²½ë¡œëŠ” ì™„ì „íˆ save_dirë¡œ ê°•ì œë¨
    """
    save_dir = os.path.abspath(save_dir)
    return _process_post_core(post_id, save_dir)




###########################################################
#  ë©”ì¸ ì‹¤í–‰
###########################################################
if __name__ == "__main__":
    post_url = input("CivitAI í¬ìŠ¤íŠ¸ URL ì…ë ¥: ").strip()

    m = re.search(r"/posts/(\d+)", post_url)
    if not m:
        print("URLì—ì„œ postId ì¶”ì¶œ ì‹¤íŒ¨")
        raise SystemExit

    post_id = int(m.group(1))
    process_post(post_id)